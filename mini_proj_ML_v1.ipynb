{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import os.path\n",
    "\n",
    "\n",
    "## File modification\n",
    "# This aims to standardize the two files so they can be preprocessed in the same way.\n",
    "\n",
    "def hf_add_definitions(input_file_name, output_file_name, definition) :  # Axel PYTHOUD\n",
    "    input_file = open(input_file_name,\"r\")\n",
    "    text = definition + \"\\n\" + input_file.read()\n",
    "    input_file.close()\n",
    "    \n",
    "    output_file = open(output_file_name, \"w\")\n",
    "    output_file.write(text)\n",
    "    output_file.close()\n",
    "    \n",
    "    \n",
    "def hf_remove_characters(text, characters) :  # Axel PYTHOUD\n",
    "    \n",
    "    for character in characters : \n",
    "        text = text.replace(character,'')\n",
    "    \n",
    "    return text\n",
    "\n",
    "def hf_remove_id(input_file_name) :  # Axel PYTHOUD\n",
    "    input_file = open(input_file_name,\"r\")\n",
    "    text = \"\"\n",
    "    \n",
    "    for line in input_file : \n",
    "        text += line[line.index(',') + 1:]\n",
    "        \n",
    "    input_file.close()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def hf_prepare_kidney_file(input_file_name, output_file_name) :  # Axel PYTHOUD\n",
    "    text = hf_remove_id(input_file_name) #This removes the id column\n",
    "    text = hf_remove_characters(text, [\"\\t\", \"?\", ' ']) #This removes tabs, question marks, and spaces from the file\n",
    "    \n",
    "    output_file = open(output_file_name, \"w\")\n",
    "    output_file.write(text)\n",
    "    output_file.close()\n",
    "\n",
    "unprepared_banknote_file_name = \"data_banknote_authentication.txt\"\n",
    "banknote_file_name = \"data_banknote_authentication_with_def.csv\"\n",
    "if not(os.path.exists(banknote_file_name)) :\n",
    "    hf_add_definitions(unprepared_banknote_file_name, banknote_file_name, \"variance,skewness,curtosis,entropy,class\") #This adds a definition to the file\n",
    "\n",
    "unprepared_kidney_file_name = \"archive/kidney_disease.csv\"\n",
    "kidney_file_name = \"archive/kidney_disease_cleaned.csv\"\n",
    "if not(os.path.exists(kidney_file_name)) :\n",
    "    hf_prepare_kidney_file(unprepared_kidney_file_name, kidney_file_name) #This removes tabs, question marks, and spaces from the file\n",
    "    \n",
    "\n",
    "## Import the files into pandas dataframes\n",
    "\n",
    "def import_file(file_name, separator) :     # Axel PYTHOUD\n",
    "    pd_data = pd.read_csv(file_name, sep = separator)\n",
    "    return pd_data\n",
    "    \n",
    "banknote_pd_data = import_file(banknote_file_name, \",\")    \n",
    "kidney_pd_data = import_file(kidney_file_name, \",\")\n",
    "\n",
    "\n",
    "## Clean dataframes\n",
    "# Add missing values\n",
    "# Center and reduce columns\n",
    "\n",
    "def hf_get_mean_value(column) :  # Axel PYTHOUD\n",
    "    #Help function that returns the mean value of the column.\n",
    "    #For non numeric data types, returns the most frequent value.\n",
    "    if is_numeric_dtype(column) :\n",
    "        return column.mean()\n",
    "    else :\n",
    "        values = pd.value_counts(column)\n",
    "        return values.idxmax()\n",
    "        \n",
    "def drop_column(pd_data):  #Alina CIOCARLAN\n",
    "    c = pd_data.columns\n",
    "    empty = (pd_data.isnull().sum() / len(pd_data)) * 100\n",
    "\n",
    "    for i in range(len(empty)):\n",
    "        if empty[i] > 30: #drop column if percentage of missing values is above 30%\n",
    "            c_to_drop = c[i]\n",
    "            pd_data = pd_data.drop(c_to_drop, 1)\n",
    "    return pd_data\n",
    "\n",
    "        \n",
    "def clean_dataframe(pd_data) :  # Axel PYTHOUD\n",
    "    pd_data = drop_column(pd_data)\n",
    "    \n",
    "    column_names = pd_data.columns\n",
    "    number_of_columns = column_names.size\n",
    "    means = []\n",
    "    \n",
    "    for col_name in column_names :\n",
    "        means.append(hf_get_mean_value(pd_data[col_name]))\n",
    "       \n",
    "    # We have the means of each column of the dataset\n",
    "    # Now we find the cells that are not filled, and replace them with the mean value of the column.\n",
    "    null_data = np.where(pd.isnull(pd_data))\n",
    "    for i in range(len(null_data[0])) :\n",
    "        row = null_data[0][i]\n",
    "        col_id = null_data[1][i]\n",
    "        col = column_names[col_id]\n",
    "        pd_data.at[row,col] = means[col_id]\n",
    "    \n",
    "    # Our cells are all filled now.\n",
    "    # We can center and reduce the values of the numeric columns\n",
    "    L=list(pd_data.columns)[:-1] #function applied on all numerical values except the last class\n",
    "    pd_data[L] = pd_data[L].apply(lambda x : (x - x.mean()) / np.sqrt(x.var() + 10**-9) if is_numeric_dtype(x) else x) #The value 10**-9 is a safety to ensure we don't divide by 0.\n",
    "    \n",
    "    return pd_data\n",
    "\n",
    "kidney_pd_data = clean_dataframe(kidney_pd_data)\n",
    "banknote_pd_data = clean_dataframe(banknote_pd_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age        bp        sg        al        su        pc         pcc  \\\n",
      "0 -0.205207  0.262010  0.482742 -0.013321 -0.437249    normal  notpresent   \n",
      "1 -2.620528 -1.964120  0.482742  2.344580 -0.437249    normal  notpresent   \n",
      "2  0.619537  0.262010 -1.379639  0.772646  2.476824    normal  notpresent   \n",
      "3 -0.205207 -0.480033 -2.310829  2.344580 -0.437249  abnormal     present   \n",
      "4 -0.028476  0.262010 -1.379639  0.772646 -0.437249    normal  notpresent   \n",
      "\n",
      "           ba       bgr        bu  ...      hemo       pcv        wc  htn  \\\n",
      "0  notpresent -0.361535 -0.434723  ...  1.057946  0.627586 -0.240218  yes   \n",
      "1  notpresent  0.000000 -0.799939  ... -0.451531 -0.108513 -0.953592   no   \n",
      "2  notpresent  3.676836 -0.089797  ... -1.077412 -0.967295 -0.359114   no   \n",
      "3  notpresent -0.415023 -0.028928  ... -0.488348 -0.844612 -0.676169  yes   \n",
      "4  notpresent -0.562116 -0.637621  ... -0.341082 -0.476562 -0.438377   no   \n",
      "\n",
      "    dm  cad appet   pe  ane classification  \n",
      "0  yes   no  good   no   no            ckd  \n",
      "1   no   no  good   no   no            ckd  \n",
      "2  yes   no  poor   no  yes            ckd  \n",
      "3   no   no  poor  yes  yes            ckd  \n",
      "4   no   no  good   no   no            ckd  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "0         ckd\n",
      "1         ckd\n",
      "2         ckd\n",
      "3         ckd\n",
      "4         ckd\n",
      "        ...  \n",
      "395    notckd\n",
      "396    notckd\n",
      "397    notckd\n",
      "398    notckd\n",
      "399    notckd\n",
      "Name: classification, Length: 400, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(kidney_pd_data.head())\n",
    "print(kidney_pd_data['classification'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a beaucoup trop de colonnes donc il va falloir faire une PCA. Et il faut aussi transformer tous les features categorical en discrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   variance  skewness  curtosis   entropy  class\n",
      "0  1.121397  1.149036 -0.975614  0.354432      0\n",
      "1  1.446538  1.064065 -0.894710 -0.128721      0\n",
      "2  1.207369 -0.777069  0.122174  0.617848      0\n",
      "3  1.063355  1.295005 -1.254940 -1.143612      0\n",
      "4 -0.036758 -1.086642  0.736462  0.096552      0\n"
     ]
    }
   ],
   "source": [
    "print(banknote_pd_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical data to discrete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def label_encoding(pd_df): #Alina CIOCARLAN\n",
    "    \n",
    "    c=pd_df.columns\n",
    "    types=list(pd_df.dtypes)\n",
    "    for i in range(len(c)):\n",
    "        if types[i] == 'O': #there are only 2 types here, if it's of type 'O', we have to transform it into numerical\n",
    "            lab_encod = LabelEncoder()\n",
    "            pd_df[c[i]] = lab_encod.fit_transform(pd_df[c[i]])\n",
    "         \n",
    "label_encoding(kidney_pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age        bp        sg        al        su  pc  pcc  ba       bgr  \\\n",
      "0 -0.205207  0.262010  0.482742 -0.013321 -0.437249   1    0   0 -0.361535   \n",
      "1 -2.620528 -1.964120  0.482742  2.344580 -0.437249   1    0   0  0.000000   \n",
      "2  0.619537  0.262010 -1.379639  0.772646  2.476824   1    0   0  3.676836   \n",
      "3 -0.205207 -0.480033 -2.310829  2.344580 -0.437249   0    1   0 -0.415023   \n",
      "4 -0.028476  0.262010 -1.379639  0.772646 -0.437249   1    0   0 -0.562116   \n",
      "\n",
      "         bu  ...      hemo       pcv        wc  htn  dm  cad  appet  pe  ane  \\\n",
      "0 -0.434723  ...  1.057946  0.627586 -0.240218    1   1    0      0   0    0   \n",
      "1 -0.799939  ... -0.451531 -0.108513 -0.953592    0   0    0      0   0    0   \n",
      "2 -0.089797  ... -1.077412 -0.967295 -0.359114    0   1    0      1   0    1   \n",
      "3 -0.028928  ... -0.488348 -0.844612 -0.676169    1   0    0      1   1    1   \n",
      "4 -0.637621  ... -0.341082 -0.476562 -0.438377    0   0    0      0   0    0   \n",
      "\n",
      "   classification  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "395    1\n",
      "396    1\n",
      "397    1\n",
      "398    1\n",
      "399    1\n",
      "Name: classification, Length: 400, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(kidney_pd_data.head())\n",
    "print(kidney_pd_data['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def PCA_on_df(df,seuil): #Alina CIOCARLAN\n",
    "    pca=PCA()\n",
    "    pca.fit(df)\n",
    "    df=pca.transform(df)\n",
    "    cumulative_pca=pca.explained_variance_ratio_.cumsum()\n",
    "    n=0\n",
    "    for e in cumulative_pca:\n",
    "        if e<seuil:\n",
    "            n+=1\n",
    "    df = df[:, :n]\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0 -1.118114  0.018732  0.210450  0.197741  0.283720 -0.121380  0.154483   \n",
      "1 -0.667419  0.637700 -1.118999 -0.630814 -2.931895 -1.916005 -0.923634   \n",
      "2  3.027171 -3.132784  1.028278  0.792919 -0.522101 -1.306855 -0.842645   \n",
      "3  2.629734  1.229987 -1.975479  1.207339 -1.001311 -1.016230 -1.266714   \n",
      "4  0.311846  0.112979 -0.897809 -0.487577  0.198846 -0.651995 -0.498655   \n",
      "\n",
      "          7         8         9  \n",
      "0 -0.029340  0.692544  0.214566  \n",
      "1 -0.827027  0.950454  0.624493  \n",
      "2 -0.119248 -0.908876  0.017875  \n",
      "3  1.286312  1.808054  0.442168  \n",
      "4  1.312279  0.514110  0.087847  \n"
     ]
    }
   ],
   "source": [
    "L=list(kidney_pd_data.columns)[:-1]\n",
    "df_proj=PCA_on_df(kidney_pd_data[L],0.9)\n",
    "print(df_proj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0 -1.472268 -1.163492 -0.167193\n",
      "1 -1.638843 -1.093413  0.371052\n",
      "2  0.513732 -1.324397  0.508926\n",
      "3 -2.310110 -0.202441  0.540584\n",
      "4  1.192981  0.024645  0.421036\n"
     ]
    }
   ],
   "source": [
    "L=list(banknote_pd_data.columns)[:-1]\n",
    "df_proj_bis=PCA_on_df(banknote_pd_data[L],0.97)\n",
    "print(df_proj_bis.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Alina CIOCARLAN\n",
    "\n",
    "# split dataset kidney disease\n",
    "dataX=np.array(df_proj)\n",
    "dataY=np.array(kidney_pd_data['classification'])\n",
    "train_ratio = 0.75\n",
    "# we split the dataset in 2 : one part for training/validation set (we'll do K-fold validation right after),\n",
    "# the other for test set\n",
    "def data_split(dataX,dataY,train_ratio): #Alina CIOCARLAN\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataX,dataY , test_size=1 - train_ratio)\n",
    " \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test=data_split(dataX,dataY,train_ratio)\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=True) #10 is a common number on large datasets (validate on 10% on dataset each time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 29,641\n",
      "Trainable params: 29,129\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/sample - loss: 0.4058 - accuracy: 0.9000\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 0.0881 - accuracy: 0.9889\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0729 - accuracy: 0.9889\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 0.0221 - accuracy: 0.9926\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0180 - accuracy: 0.9963\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 207us/sample - loss: 0.0195 - accuracy: 0.9926\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0117 - accuracy: 0.9926\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 0.1039 - accuracy: 0.9778\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0279 - accuracy: 0.9889\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0177 - accuracy: 0.9963\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0212 - accuracy: 0.9889\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 176us/sample - loss: 0.0095 - accuracy: 0.9963\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0100 - accuracy: 0.9963\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 0.0047 - accuracy: 0.9963\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 0.0079 - accuracy: 0.9963\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0142 - accuracy: 0.9926\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0243 - accuracy: 0.9889\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0213 - accuracy: 0.9926\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0775 - accuracy: 0.9852\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0133 - accuracy: 0.9926\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0186 - accuracy: 0.9926\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0102 - accuracy: 0.9926\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0100 - accuracy: 0.9963\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0658 - accuracy: 0.9926\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0042 - accuracy: 0.9963\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0077 - accuracy: 0.9963\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0208 - accuracy: 0.9852\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0078 - accuracy: 0.9926\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 171us/sample - loss: 0.0098 - accuracy: 0.9963\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0176 - accuracy: 0.9926\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0214 - accuracy: 0.9889\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0245 - accuracy: 0.9889\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0067 - accuracy: 0.9963\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0080 - accuracy: 0.9963\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0030 - accuracy: 0.9963\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0051 - accuracy: 0.9963\n",
      "Score for fold 1: loss of 0.06868096441030502; accuracy of 93.33333373069763%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        20\n",
      "           1       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.95      0.90      0.92        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 0.2424 - accuracy: 0.9222\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 203us/sample - loss: 0.0258 - accuracy: 0.9926\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0727 - accuracy: 0.9963\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0431 - accuracy: 0.9815\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0194 - accuracy: 0.9889\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 184us/sample - loss: 0.0170 - accuracy: 0.9963\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 0.0112 - accuracy: 0.9963\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 0.1277 - accuracy: 0.9852\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 0.0100 - accuracy: 0.9963\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 211us/sample - loss: 0.0086 - accuracy: 0.9963\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 0.0705 - accuracy: 0.9926\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 199us/sample - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 8.0664e-04 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 179us/sample - loss: 0.0075 - accuracy: 0.9963\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 160us/sample - loss: 0.0043 - accuracy: 0.9963\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0125 - accuracy: 0.9889\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0591 - accuracy: 0.9963\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0324 - accuracy: 0.9926\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.4053 - accuracy: 0.9481\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.2485 - accuracy: 0.9741\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0397 - accuracy: 0.9852\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0721 - accuracy: 0.9889\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0738 - accuracy: 0.9889\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0195 - accuracy: 0.9889\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0113 - accuracy: 0.9926\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0196 - accuracy: 0.9963\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0266 - accuracy: 0.9815\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0137 - accuracy: 0.9926\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0218 - accuracy: 0.9889\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0797 - accuracy: 0.9852\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0463 - accuracy: 0.9815\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0229 - accuracy: 0.9926\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0037 - accuracy: 0.9963\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 0.0106 - accuracy: 0.9963\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 182us/sample - loss: 0.0150 - accuracy: 0.9889\n",
      "Score for fold 2: loss of 0.5182266235351562; accuracy of 96.66666388511658%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        18\n",
      "           1       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 0.1941 - accuracy: 0.9444\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 153us/sample - loss: 0.1148 - accuracy: 0.9741\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0365 - accuracy: 0.9815\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0225 - accuracy: 0.9963\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0198 - accuracy: 0.9963\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0754 - accuracy: 0.9889\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0216 - accuracy: 0.9963\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0225 - accuracy: 0.9852\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 173us/sample - loss: 0.0097 - accuracy: 0.9963\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0129 - accuracy: 0.9926\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 165us/sample - loss: 0.0825 - accuracy: 0.9815\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 167us/sample - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0287 - accuracy: 0.9852\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 156us/sample - loss: 0.0826 - accuracy: 0.9889\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 158us/sample - loss: 0.0092 - accuracy: 0.9963\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 169us/sample - loss: 0.0077 - accuracy: 0.9963\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0165 - accuracy: 0.9926\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0262 - accuracy: 0.9815\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 164us/sample - loss: 0.0079 - accuracy: 0.9963\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 164us/sample - loss: 0.0055 - accuracy: 0.9963\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 179us/sample - loss: 0.0113 - accuracy: 0.9963\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 168us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0071 - accuracy: 0.9963\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0124 - accuracy: 0.9926\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0344 - accuracy: 0.9815\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 164us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0080 - accuracy: 0.9963\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0080 - accuracy: 0.9963\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 167us/sample - loss: 0.0122 - accuracy: 0.9926\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0062 - accuracy: 0.9963\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 153us/sample - loss: 0.0690 - accuracy: 0.9963\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0881 - accuracy: 0.9815\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0168 - accuracy: 0.9889\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 154us/sample - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 160us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 8.5754e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0128 - accuracy: 0.9926\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 158us/sample - loss: 0.0077 - accuracy: 0.9963\n",
      "Score for fold 3: loss of 0.0; accuracy of 100.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 3ms/sample - loss: 0.1939 - accuracy: 0.9111\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 180us/sample - loss: 0.0573 - accuracy: 0.9778\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0410 - accuracy: 0.9741\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0299 - accuracy: 0.9852\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 150us/sample - loss: 0.0163 - accuracy: 0.9963\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 158us/sample - loss: 0.0123 - accuracy: 0.9963\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 157us/sample - loss: 0.0717 - accuracy: 0.9889\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 158us/sample - loss: 0.0232 - accuracy: 0.9889\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 154us/sample - loss: 0.0774 - accuracy: 0.9852\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0114 - accuracy: 0.9926\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0152 - accuracy: 0.9926\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 156us/sample - loss: 0.0192 - accuracy: 0.9926\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 154us/sample - loss: 0.0208 - accuracy: 0.9926\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 158us/sample - loss: 0.0961 - accuracy: 0.9778\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0682 - accuracy: 0.9704\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0308 - accuracy: 0.9852\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 157us/sample - loss: 0.0933 - accuracy: 0.9815\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0204 - accuracy: 0.9926\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0274 - accuracy: 0.9889\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 185us/sample - loss: 0.0164 - accuracy: 0.9889\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 187us/sample - loss: 0.0730 - accuracy: 0.9889\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 184us/sample - loss: 0.0081 - accuracy: 0.9963\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 0.0116 - accuracy: 0.9926\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0068 - accuracy: 0.9963\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 167us/sample - loss: 0.0149 - accuracy: 0.9963\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0095 - accuracy: 0.9963\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 158us/sample - loss: 0.0773 - accuracy: 0.9889\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 164us/sample - loss: 0.0165 - accuracy: 0.9963\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0139 - accuracy: 0.9963\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0062 - accuracy: 0.9963\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0029 - accuracy: 0.9963\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0116 - accuracy: 0.9926\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0245 - accuracy: 0.9889\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0079 - accuracy: 0.9963\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0174 - accuracy: 0.9926\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0087 - accuracy: 0.9963\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0100 - accuracy: 0.9926\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 160us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0075 - accuracy: 0.9963\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 165us/sample - loss: 5.5702e-04 - accuracy: 1.0000\n",
      "Score for fold 4: loss of 0.001513208495453; accuracy of 100.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 0.2627 - accuracy: 0.9000\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 0.0766 - accuracy: 0.9667\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 0.0371 - accuracy: 0.9926\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 0.0755 - accuracy: 0.9963\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0373 - accuracy: 0.9889\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0518 - accuracy: 0.9778\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0527 - accuracy: 0.9778\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0132 - accuracy: 0.9963\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0872 - accuracy: 0.9852\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0188 - accuracy: 0.9889\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0107 - accuracy: 0.9963\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 146us/sample - loss: 0.0877 - accuracy: 0.9852\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 154us/sample - loss: 0.0209 - accuracy: 0.9889\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0199 - accuracy: 0.9889\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 0.0113 - accuracy: 0.9963\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0196 - accuracy: 0.9926\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0633 - accuracy: 0.9926\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0087 - accuracy: 0.9926\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 153us/sample - loss: 0.0105 - accuracy: 0.9963\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 154us/sample - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0156 - accuracy: 0.9963\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0152 - accuracy: 0.9963\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 164us/sample - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 156us/sample - loss: 0.0236 - accuracy: 0.9926\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 150us/sample - loss: 0.0207 - accuracy: 0.9963\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 150us/sample - loss: 0.0105 - accuracy: 0.9963\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0083 - accuracy: 0.9926\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0613 - accuracy: 0.9926\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0290 - accuracy: 0.9815\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 157us/sample - loss: 0.0108 - accuracy: 0.9926\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0165 - accuracy: 0.9852\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 164us/sample - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0142 - accuracy: 0.9963\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 158us/sample - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 158us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 192us/sample - loss: 0.0056 - accuracy: 0.9963\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0187 - accuracy: 0.9963\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 9.5205e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 1.3263e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Score for fold 5: loss of 0.0; accuracy of 100.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 0.4117 - accuracy: 0.8185\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0847 - accuracy: 0.9667\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0782 - accuracy: 0.9630\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0277 - accuracy: 0.9963\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0387 - accuracy: 0.9926\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0298 - accuracy: 0.9926\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0255 - accuracy: 0.9889\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 156us/sample - loss: 0.0234 - accuracy: 0.9889\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0440 - accuracy: 0.9815\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0087 - accuracy: 0.9963\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0202 - accuracy: 0.9889\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 167us/sample - loss: 0.0146 - accuracy: 0.9926\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 157us/sample - loss: 0.0223 - accuracy: 0.9963\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0163 - accuracy: 0.9963\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0244 - accuracy: 0.9852\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0179 - accuracy: 0.9926\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0178 - accuracy: 0.9963\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 160us/sample - loss: 0.0099 - accuracy: 0.9963\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0138 - accuracy: 0.9963\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0124 - accuracy: 0.9963\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 184us/sample - loss: 0.0101 - accuracy: 0.9926\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 173us/sample - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 183us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0080 - accuracy: 0.9963\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0181 - accuracy: 0.9963\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 154us/sample - loss: 7.3977e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0139 - accuracy: 0.9963\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0074 - accuracy: 0.9963\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 3.5366e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 143us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0028 - accuracy: 0.9963\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 179us/sample - loss: 0.0041 - accuracy: 0.9963\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 187us/sample - loss: 0.0904 - accuracy: 0.9778\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 173us/sample - loss: 0.0063 - accuracy: 0.9963\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 165us/sample - loss: 0.0081 - accuracy: 0.9963\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Score for fold 6: loss of 0.0631687119603157; accuracy of 96.66666388511658%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        19\n",
      "           1       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 0.2055 - accuracy: 0.9185\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.1305 - accuracy: 0.9741\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.1109 - accuracy: 0.9667\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0939 - accuracy: 0.9741\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0396 - accuracy: 0.9815\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0289 - accuracy: 0.9889\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0756 - accuracy: 0.9926\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0295 - accuracy: 0.9889\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0193 - accuracy: 0.9963\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 0.0628 - accuracy: 0.9963\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0138 - accuracy: 0.9926\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0298 - accuracy: 0.9926\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0161 - accuracy: 0.9926\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0223 - accuracy: 0.9889\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0158 - accuracy: 0.9963\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0085 - accuracy: 0.9963\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0056 - accuracy: 0.9963\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0044 - accuracy: 0.9963\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0118 - accuracy: 0.9963\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0122 - accuracy: 0.9926\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 160us/sample - loss: 0.0161 - accuracy: 0.9963\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0106 - accuracy: 0.9963\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 8.5923e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 0.0108 - accuracy: 0.9963\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 244us/sample - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 384us/sample - loss: 0.1302 - accuracy: 0.9852\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0087 - accuracy: 0.9963\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 0.0057 - accuracy: 0.9963\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0210 - accuracy: 0.9926\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0072 - accuracy: 0.9963\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0039 - accuracy: 0.9963\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 9.8374e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 1.1380e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0045 - accuracy: 1.0000\n",
      "Score for fold 7: loss of 0.04358626529574394; accuracy of 96.66666388511658%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 0.4449 - accuracy: 0.8667\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0610 - accuracy: 0.9778\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0244 - accuracy: 0.9889\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0294 - accuracy: 0.9926\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0282 - accuracy: 0.9852\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0896 - accuracy: 0.9852\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0308 - accuracy: 0.9889\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0174 - accuracy: 0.9926\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0333 - accuracy: 0.9889\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0243 - accuracy: 0.9926\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 0.0797 - accuracy: 0.9815\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0193 - accuracy: 0.9963\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0229 - accuracy: 0.9926\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 325us/sample - loss: 0.0276 - accuracy: 0.9852\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 211us/sample - loss: 0.0693 - accuracy: 0.9926\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0676 - accuracy: 0.9963\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0243 - accuracy: 0.9889\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0165 - accuracy: 0.9889\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0164 - accuracy: 0.9889\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0125 - accuracy: 0.9926\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0650 - accuracy: 0.9963\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0207 - accuracy: 0.9963\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.3189 - accuracy: 0.9704\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.3275 - accuracy: 0.9444\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.1457 - accuracy: 0.9852\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0302 - accuracy: 0.9852\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.1236 - accuracy: 0.9889\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0917 - accuracy: 0.9815\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.1969 - accuracy: 0.9704\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.1425 - accuracy: 0.9852\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.1787 - accuracy: 0.9815\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 380us/sample - loss: 0.1219 - accuracy: 0.9889\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0172 - accuracy: 0.9889\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.1280 - accuracy: 0.9852\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0098 - accuracy: 0.9926\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0230 - accuracy: 0.9889\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0678 - accuracy: 0.9889\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0666 - accuracy: 0.9889\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0293 - accuracy: 0.9852\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0130 - accuracy: 0.9926\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0120 - accuracy: 0.9926\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0069 - accuracy: 1.0000\n",
      "Score for fold 8: loss of 0.0; accuracy of 100.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 0.2325 - accuracy: 0.8963\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 157us/sample - loss: 0.1161 - accuracy: 0.9667\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0373 - accuracy: 0.9815\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 154us/sample - loss: 0.0218 - accuracy: 0.9889\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 171us/sample - loss: 0.0694 - accuracy: 0.9926\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 158us/sample - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.1448 - accuracy: 0.9852\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 177us/sample - loss: 0.0141 - accuracy: 0.9963\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0676 - accuracy: 0.9963\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0154 - accuracy: 0.9926\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 0.0849 - accuracy: 0.9815\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0127 - accuracy: 0.9963\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 175us/sample - loss: 0.0171 - accuracy: 0.9963\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 180us/sample - loss: 0.0165 - accuracy: 0.9889\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 168us/sample - loss: 0.0086 - accuracy: 0.9963\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 347us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 153us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0139 - accuracy: 0.9926\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0041 - accuracy: 0.9963\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 150us/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 156us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 164us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 179us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 152us/sample - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0102 - accuracy: 0.9926\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 164us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 4.6029e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 157us/sample - loss: 9.4371e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 164us/sample - loss: 2.8970e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0192 - accuracy: 0.9926\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0131 - accuracy: 0.9926\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0144 - accuracy: 0.9889\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 210us/sample - loss: 0.0637 - accuracy: 0.9963\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 281us/sample - loss: 0.0065 - accuracy: 0.9963\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 173us/sample - loss: 0.0215 - accuracy: 0.9889\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Score for fold 9: loss of 0.020273583009839058; accuracy of 100.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Train on 270 samples\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 0.1728 - accuracy: 0.9444\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 161us/sample - loss: 0.0467 - accuracy: 0.9852\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0928 - accuracy: 0.9815\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0242 - accuracy: 0.9926\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0162 - accuracy: 0.9926\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 160us/sample - loss: 0.1314 - accuracy: 0.9852\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0107 - accuracy: 0.9963\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0426 - accuracy: 0.9815\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0109 - accuracy: 0.9963\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0111 - accuracy: 0.9963\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 176us/sample - loss: 0.0199 - accuracy: 0.9963\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0874 - accuracy: 0.9852\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0060 - accuracy: 0.9963\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0067 - accuracy: 0.9963\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0745 - accuracy: 0.9926\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 0.0153 - accuracy: 0.9926\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0328 - accuracy: 0.9815\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0170 - accuracy: 0.9926\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 255us/sample - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 285us/sample - loss: 0.0164 - accuracy: 0.9926\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0723 - accuracy: 0.9963\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 188us/sample - loss: 0.0158 - accuracy: 0.9926\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.1730 - accuracy: 0.9704\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.2517 - accuracy: 0.9481\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0416 - accuracy: 0.9889\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0693 - accuracy: 0.9889\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0698 - accuracy: 0.9889\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0148 - accuracy: 0.9963\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0140 - accuracy: 0.9963\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0241 - accuracy: 0.9926\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0163 - accuracy: 0.9926\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0177 - accuracy: 0.9926\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0117 - accuracy: 0.9963\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0130 - accuracy: 0.9926\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 162us/sample - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 163us/sample - loss: 0.0070 - accuracy: 0.9963\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 321us/sample - loss: 0.0055 - accuracy: 0.9963\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 196us/sample - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0105 - accuracy: 0.9963\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 155us/sample - loss: 0.0249 - accuracy: 0.9889\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 166us/sample - loss: 0.0075 - accuracy: 0.9963\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 181us/sample - loss: 0.0124 - accuracy: 0.9889\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 174us/sample - loss: 0.0042 - accuracy: 1.0000\n",
      "Score for fold 10: loss of 0.0; accuracy of 100.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.06868096441030502 - Accuracy: 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.5182266235351562 - Accuracy: 96.66666388511658%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.0 - Accuracy: 100.0%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.001513208495453 - Accuracy: 100.0%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.0 - Accuracy: 100.0%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 0.0631687119603157 - Accuracy: 96.66666388511658%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 0.04358626529574394 - Accuracy: 96.66666388511658%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 0.0 - Accuracy: 100.0%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 0.020273583009839058 - Accuracy: 100.0%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 0.0 - Accuracy: 100.0%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 98.33333253860474 (+- 2.2360685106202576)\n",
      "> Loss: 0.07154493567068129\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Alina CIOCARLAN\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(256, input_dim=10, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(.15))\n",
    "model.add(Dense(1, activation='hard_sigmoid'))\n",
    "\n",
    "model.summary()  # get a summary of the model (better understanding)\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_nb = 1\n",
    "for train, test in kf.split(x_train, y_train):\n",
    "  # Define the model architecture\n",
    "    model=Sequential()\n",
    "    model.add(Dense(256, input_dim=10, activation='relu'))\n",
    "    model.add(BatchNormalization())  # add batch normalization to avoid overfitting\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(.15)) # same effect as batch normalization but the concept is different \n",
    "    #(we don't count the answer of 15% of the neurons (randomly chosen) during the training only\n",
    "    model.add(Dense(1, activation='hard_sigmoid'))\n",
    "    \n",
    "  # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_nb} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "    history=model.fit(x_train[train], y_train[train],epochs=50, batch_size=20)\n",
    "\n",
    "  # evaluate and get metrics\n",
    "    scores = model.evaluate(x_train[test], y_train[test], verbose=0)\n",
    "    y_pred=model.predict_classes(x_train[test])\n",
    "    print(f'Score for fold {fold_nb}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    print(classification_report(y_train[test], y_pred))\n",
    "  # Increase fold number\n",
    "    fold_nb = fold_nb + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        68\n",
      "           1       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.95      0.95      0.95       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test=model.predict_classes(x_test)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
